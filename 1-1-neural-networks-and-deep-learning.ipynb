{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "\n",
    "Examples\n",
    "- home features -> price: **NN**\n",
    "- ad, user info -> click on ad? (0,1): **NN**\n",
    "- image -> object$(1\\dots1000)$: **CNN**\n",
    "- audio -> text transcript: **RNN**\n",
    "- english -> chinese: **RNN**\n",
    "- image, radar info -> position of other cars: **Hybrid**\n",
    "\n",
    "Data\n",
    "- structured data\n",
    "- unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "\n",
    "- $m$ training examples: $\\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}) \\dots (x^{(m)}, y^{(m)})\\}$\n",
    "\n",
    "$X = \n",
    "\\begin{bmatrix}\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\ \n",
    "    X^{(1)} & X^{(2)} \\ldots & X^{(m)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\\n",
    "    \\vdots & \\vdots & \\vdots \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $X \\in {\\rm I\\!R^{n_{x}, m}}$\n",
    "- $X$.shape = $(n_{x}, m)$\n",
    "\n",
    "$Y = \n",
    "\\begin{bmatrix}\n",
    "    Y^{(1)} & Y^{(2)} \\ldots & Y^{(m)} \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $Y \\in {\\rm I\\!R^{1, m}}$\n",
    "- $Y$.shape = $(1, m)$\n",
    "\n",
    "## Logistic regression\n",
    "\n",
    "- given $x$, want $\\hat{y} = P(y=1|x)$ (where $x \\in {\\rm I\\!R^{n_{x}}}$ and $0 \\le \\hat{y} \\le 1$)\n",
    "- parameters: $w \\in {\\rm I\\!R^{n_{x}}}$, $b \\in {\\rm I\\!R}$\n",
    "- output $\\hat{y} = \\sigma{(w^{T}x + b)}$\n",
    "\n",
    "$\\sigma{(z)} = \\dfrac{1}{1+e^{-z}}$\n",
    "- if $z$ large positive, $\\sigma{(z)} \\approx 1$\n",
    "- if $z$ large negative, $\\sigma{(z)} \\approx 0$\n",
    "\n",
    "## Loss function\n",
    "\n",
    "- $L(\\hat{y}, y) = -(ylog\\hat{y} + (1-y)log(1-\\hat{y}))$\n",
    "- if $y = 1$, $L(\\hat{y}, y) = -log\\hat{y}$ => want $\\hat{y}$ large as possible ($y \\approx 1$)\n",
    "- if $y = 0$, $L(\\hat{y}, y) = -log(1-\\hat{y})$ => want $\\hat{y}$ small as possible ($y \\approx 0$)\n",
    "\n",
    "## Cost function\n",
    "\n",
    "$J(w,b) = \\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}L(\\hat{y}^{(i)}, y^{(i)})$ = $\\dfrac{1}{m}\\displaystyle\\sum_{i=1}^{m}-(y^{(i)}log\\hat{y}^{(i)} + (1-y^{(i)})log(1-\\hat{y}^{(i)}))$\n",
    "\n",
    "## Gradient descent\n",
    "\n",
    "- want $w,b$ that minimizes $J(w,b)$\n",
    "- $w := w - \\alpha\\dfrac{\\partial J(w,b)}{\\partial w}$\n",
    "- $b := b - \\alpha\\dfrac{\\partial J(w,b)}{\\partial b}$\n",
    "\n",
    "## Logistic regression gradient descent\n",
    "\n",
    "- $z = w^{T} + b$\n",
    "- $y = a = \\sigma(z)$\n",
    "- $L(a,y) = -(ylog(a) + (1-y)log(1-a))$\n",
    "\n",
    "Example with 2 features with a single training example\n",
    "\n",
    "- parameters: $x_{1}, w_{1}, x_{2}, w_{2}, b$\n",
    "- $z = w_{1}x_{1} + w_{2}x_{2} + b$\n",
    "- $a = \\sigma(z)$\n",
    "- $L(a,y)$\n",
    "\n",
    "Derivatives\n",
    "\n",
    "- $da = \\dfrac{\\partial L(a,y)}{\\partial a} = -\\dfrac{y}{a} + \\dfrac{1-y}{1-a}$\n",
    "- $dz = \\dfrac{\\partial L(a,y)}{\\partial z} = \\dfrac{\\partial L(a,y)}{\\partial a}\\dfrac{\\partial a}{\\partial z} = \\left(-\\dfrac{y}{a} + \\dfrac{1-y}{1-a}\\right)a(1-a) = a - z$ \n",
    "- $dw_{1} = x_{1}dz$\n",
    "- $dw_{2} = x_{2}dz$\n",
    "- $db = dz$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/convolutional-neural-network/SIGNS.png\" style=\"width:800px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 6\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "conv_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, X, Y):\n",
    "        tf.random.set_seed(1)\n",
    "        xavier_initializer = tf.initializers.GlorotUniform()\n",
    "        self.W1 = tf.Variable(xavier_initializer(shape=[4, 4, 3, 8]), dtype='float32')\n",
    "        self.W2 = tf.Variable(xavier_initializer(shape=[2, 2, 8, 16]), dtype='float32')\n",
    "             \n",
    "    def __call__(self, X):\n",
    "        # CONV2D: stride of 1, padding 'SAME'\n",
    "        self.Z1 = tf.nn.conv2d(X, self.W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "        print(\"Z1: \" + str(self.Z1.shape))\n",
    "        \n",
    "        # RELU\n",
    "        self.A1 = tf.nn.relu(self.Z1)\n",
    "        print(\"A1: \" + str(self.A1.shape))\n",
    "        \n",
    "        # MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "        self.P1 = tf.nn.max_pool(self.A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "        print(\"P1: \" + str(self.P1.shape))\n",
    "        \n",
    "        # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "        self.Z2 = tf.nn.conv2d(self.P1, self.W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "        print(\"Z2: \" + str(self.Z2.shape))\n",
    "        \n",
    "        # RELU\n",
    "        self.A2 = tf.nn.relu(self.Z2)\n",
    "        print(\"A2: \" + str(self.A2.shape))\n",
    "        \n",
    "        # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "        self.P2 = tf.nn.max_pool(self.A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "        print(\"P2: \" + str(self.P2.shape))\n",
    "        \n",
    "        # FLATTEN\n",
    "        self.F = tf.keras.layers.Flatten()(self.P2)\n",
    "        print(\"F: \" + str(self.F.shape))\n",
    "        \n",
    "        # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "        # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "        self.Z3 = tf.keras.layers.Dense(self.F,activation=None)\n",
    "        #self.Z3 = tf.contrib.layers.fully_connected(self.F, 6, activation_fn=None)\n",
    "        \n",
    "        return self.Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs):\n",
    "    \"\"\"\n",
    "    Trains the model\n",
    "    \n",
    "    Args:\n",
    "    model -- Model object defined above\n",
    "    inputs -- X_train input of training data\n",
    "    outputs -- Y_train output of training data\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = compute_cost(model(inputs), outputs)\n",
    "        grads = t.gradient(current_loss, [model.W1, model.W2])\n",
    "        optimizer.apply_gradients(zip(grads, [model.W1, model.W2]))\n",
    "        costs.append(current_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print (\"Cost after epoch %i: %f\" % (epoch, current_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "#print(\"X_train: \" + str(X_train.shape))\n",
    "#print(tf.unpack(X_train))\n",
    "\n",
    "learning_rate = 0.01\n",
    "costs = []\n",
    "num_epochs = 100\n",
    "\n",
    "model = Model(X_train, Y_train)\n",
    "optimizer = tf.optimizers.Adam(learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(model, X_train, Y_train)\n",
    "# plot the cost\n",
    "#plt.plot(np.squeeze(costs))\n",
    "#plt.ylabel('cost')\n",
    "#plt.xlabel('iterations (per fives)')\n",
    "#plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
